{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d54a06-9f1b-45ee-8638-314ecb9311af",
   "metadata": {},
   "source": [
    "# Digital image archiving, APIs, and webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1864f-bf84-43c3-9e29-2496a2409ffd",
   "metadata": {},
   "source": [
    "![gallery](gallery.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7bbbb-be35-4d3a-a473-739151329273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import getpass\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string\n",
    "punct = list(string.punctuation)\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca550473-5851-467f-b892-23472731704d",
   "metadata": {},
   "source": [
    "## How can we programmatically access images in a way that facilitates research?\n",
    "\n",
    "An API (Application Programming Interface) is a set of rules and protocols that allows different software applications to communicate with each other. It defines how requests and responses should be structured, enabling developers to access and use the functionality of another service, library, or platform without needing to understand its internal workings.\n",
    "\n",
    "APIs should be your go-to resource of choice when gathering large quantities of data, as they generally provide this data in structured form, allowing you to easily manipulate it.\n",
    "\n",
    "Microsoft makes Bing image search available as an API; so do other search providers. The Bing API is useful because it gives good metadata on the images it finds. But first, let's look at a more intuitive API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644a996-3987-44ca-95e4-41262142e92a",
   "metadata": {},
   "source": [
    "### The Project Gutenberg API\n",
    "\n",
    "[Project Gutenberg](https://www.gutenberg.org/) provides electronic copies of large variety of out-of-copyright texts. It can be accessed using the [Gutendex API](https://gutendex.com/). The `requests` library in python can be used to query this API via the relevant parameters (see the documentation for what these are).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152573a4-4ea0-4fd0-becf-f0e3aa4f2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API root url:\n",
    "\n",
    "gut = 'https://gutendex.com/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16c0b3-3a33-4787-8abd-43bca16645a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by topic (here, 'death')\n",
    "\n",
    "params = {'topic':'death'} \n",
    "death = requests.get(url = gut, params = params).json() # returns the results as a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8725a-0f72-4bb4-8b7c-b56bc97b8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad914e-7f45-4998-9261-e5c4547b9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(death['results'][2]['summaries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb746d-22cd-4657-9d46-4fadab17b141",
   "metadata": {},
   "source": [
    "### Let's create functions that allow us to access the Bing API\n",
    "\n",
    "* `search_images` gives a `dataframe` with all the relevant metadata\n",
    "* `download` images allows you to download all the images you find to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcbd01-b84f-46d2-bada-419df2c9f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY = \"c0ff1e51fbd14e598b44b3f9a76aee3d\"\n",
    "ENDPOINT = \"https://api.bing.microsoft.com/v7.0/images/search\"\n",
    "\n",
    "\n",
    "\n",
    "def search_images(query_term, num_results):\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": API_KEY}\n",
    "    params = {\"q\": query_term, \"count\": num_results}\n",
    "    response = requests.get(ENDPOINT, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return pd.DataFrame(response.json().get('value', []))\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_images(image_urls, save_dir, max_images=None):\n",
    "    # Ensure the save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Limit the number of images to download if max_images is specified\n",
    "    if max_images:\n",
    "        image_urls = image_urls[:max_images]\n",
    "    \n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            # Get the image data\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n",
    "            \n",
    "            # Define the filename and save path\n",
    "            parsed_url = urlparse(url)\n",
    "            filename = os.path.basename(parsed_url.path)\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "            \n",
    "            # Write the image data to the file\n",
    "            with open(filepath, \"wb\") as file:\n",
    "                for chunk in response.iter_content(1024):  # Download in chunks\n",
    "                    file.write(chunk)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd168acd-f48d-4a1d-927d-cc1d0f8bcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe of 10 images of Lenin\n",
    "\n",
    "images = search_images(\"lenin\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da59a8f-7241-48b9-a0e9-02629efa69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the 10 Lenin images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bfbc7-cb68-4f34-a369-302301a13f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_urls = []\n",
    "\n",
    "for i in images['contentUrl']:\n",
    "    images_urls.append(i)\n",
    "\n",
    "download_images(images_urls, \"Reform_archive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d1a26-3d24-4b24-86d6-ad68dcc751a8",
   "metadata": {},
   "source": [
    "## What can we do with this data? First, let's see if we can extract some high-level colour features across images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c3c5f-7b58-4be9-ada5-c9fed881fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_codes = ['#'+i for i in images['accentColor']] # add hash to make hex codes valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfc246ee-36d0-45f9-87c7-46db0cab8fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAABkCAIAAABM5OhcAAAChUlEQVR4Ae3SoU0DUBiF0cIMhA7CEriOgGMKpmGDug5RXYmHMACSDa74XJPz7J+bvJx8Dx+n06G+1/dLnR4+z295e4/D5+/f/O2f41Pevlyveft3+8rbx7w0JDAEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RAQ1sBx6gLC6naWQ0BYA8epCwir21kOAWENHKcuIKxuZzkEhDVwnLqAsLqd5RD4B/wkDHEFVxjEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x100>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a blank image\n",
    "width, height = 200, 100\n",
    "palette_width = width // len(hex_codes)\n",
    "image_palette = Image.new(\"RGB\", (width, height), \"white\")\n",
    "draw = ImageDraw.Draw(image_palette)\n",
    "\n",
    "# Draw each color as a rectangle\n",
    "for i, colour in enumerate(hex_codes):\n",
    "    draw.rectangle([i * palette_width, 0, (i + 1) * palette_width, height], fill=colour)\n",
    "\n",
    "#image_palette.show()  # Opens the image in a viewer\n",
    "image_palette  # Displays the image directly in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde0f23-42e8-42fe-9935-1b3d5076219b",
   "metadata": {},
   "source": [
    "## How does the text on the image webpage match the image? Let's get the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09783df4-2874-42c0-bd14-a61c8cb3a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "web_text = []\n",
    "\n",
    "for i in images['hostPageUrl']:\n",
    "    response = requests.get(i)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    cleaned_text = re.sub(r'\\n+', '\\n', text)  # Collapse multiple newlines into one\n",
    "    cleaned_text = re.sub(r'\\t+', '', cleaned_text)  # Remove tabs\n",
    "    cleaned_text = cleaned_text.strip()  # Remove leading/trailing whitespace\n",
    "    cleaned_text = word_tokenize(cleaned_text)\n",
    "    cleaned_text = [i.lower() for i in cleaned_text]\n",
    "    cleaned_text = [lemmatizer.lemmatize(i) for i in cleaned_text]\n",
    "    cleaned_text = [i for i in cleaned_text if i not in stops and i not in punct]\n",
    "    web_text.append(cleaned_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7da92b-733c-42b0-b267-0b41e22e3fe1",
   "metadata": {},
   "source": [
    "### Now, let's measure the emotional variation of the text using the VAD norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb713f-64d2-4696-9de9-13e9005cf700",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad = pd.read_csv('vad.csv', index_col = 0)  #VAD norms\n",
    "vad = vad[[\"V.Mean.Sum\", \"A.Mean.Sum\", \"D.Mean.Sum\"]]\n",
    "vad.columns = ['valence', 'arousal', 'dominance']\n",
    "\n",
    "def vad_data(word_list):\n",
    "    word_list = [i.lower() for i in word_list]\n",
    "    words = []\n",
    "    norms = []\n",
    "    \n",
    "    for i in word_list:\n",
    "        if i in vad.index:\n",
    "            norms.append(vad.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_vad = pd.DataFrame(norms).mean()\n",
    "    return norms_vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28f9a0-e053-4d1e-a66d-54545ad4fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_norms = pd.DataFrame([vad_data(i) for i in web_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0373d-6693-4183-804a-e43ad9700278",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.concat([images, web_norms], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b7b99-df4a-4ee2-a7ee-c613f37fdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaba205-796d-48c7-b599-792142b7f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = images.index, y = 'dominance', data = images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aaa57-7e8d-43a5-9190-49139b179bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
